#!/usr/bin/perl

use strict;
use warnings;
use Getopt::Long;
use File::Temp qw/ tempdir /;
use File::Path qw(remove_tree);
use FindBin '$Bin';
use lib $Bin;
use hicup_module;

use Data::Dumper;

###################################################################################
###################################################################################
##This file is Copyright (C) 2014, Steven Wingett (steven.wingett@babraham.ac.uk)##
##                                                                               ##
##                                                                               ##
##This file is part of HiCUP.                                                    ##
##                                                                               ##
##HiCUP is free software: you can redistribute it and/or modify                  ##
##it under the terms of the GNU General Public License as published by           ##
##the Free Software Foundation, either version 3 of the License, or              ##
##(at your option) any later version.                                            ##
##                                                                               ##
##HiCUP is distributed in the hope that it will be useful,                       ##
##but WITHOUT ANY WARRANTY; without even the implied warranty of                 ##
##MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                  ##
##GNU General Public License for more details.                                   ##
##                                                                               ##
##You should have received a copy of the GNU General Public License              ##
##along with HiCUP.  If not, see <http://www.gnu.org/licenses/>.                 ##
###################################################################################
###################################################################################

my $VERSION = get_version();               #Need version details in on-screen info

##########################################################
#Get user-supplied parameters
#Option variables
my %config = (
    ambiguous => '',
    config => '',
    example   => '',
    help      => '',
    keep      => '',
    nofill    => '',
    outdir    => '',
    quiet     => '',
    version   => '',
    zip       => '',
    bowtie    => '',
    bowtie2   => '',
    digest    => '',
    format    => '',
    index     => '',
    longest   => '',
    re1       => '',
    shortest  => '',
    temp      => '',
    threads   => '',
    filenames => '',
    sequence  => '',
    samtools  => '',
    r => '',
    aligner   => ''    #Not-specified by user - name of aligner to use
);

my $config_result = GetOptions(    #Stores parameters
    "ambiguous"  => \$config{ambiguous},
    "config=s"   => \$config{config},      #Keep, despite being the default
    "example"    => \$config{example},
    "help"       => \$config{help},
    "keep"       => \$config{keep},
    "nofill"     => \$config{nofill},
    "outdir=s"   => \$config{outdir},
    "version"    => \$config{version},
    "quiet"      => \$config{quiet},
    "zip"        => \$config{zip},
    "bowtie=s"   => \$config{bowtie},
    "bowtie2=s"  => \$config{bowtie2},
    "digest=s"   => \$config{digest},
    "format=s"   => \$config{format},
    "index=s"    => \$config{index},
    "longest=s"  => \$config{longest},
    "re1=s"      => \$config{re1},
    "shortest=s" => \$config{shortest},
    "temp=s"    => \$config{temp},
    "threads=s"  => \$config{threads},
    "filenames"  => \$config{filenames},
    "r=s"	=> \$config{r},
    "sequence"   => \$config{sequence},
    "samtools"   => \$config{samtools}     #Path to SAM Tools, not yet described in documentation
);

die "Command line options need to be in the correct format (hicup -help for more details).\n" unless ($config_result);

$config{help} = 1 unless( hashVal(%config) );    #Print help and exit if no command line parameters

if ( $config{help} ) {
    print while (<DATA>);
    exit(0);
}

#Print version and exit
if ( $config{version} ) {
    print "HiCUP v$VERSION\n";
    exit(0);
}

if ( $config{example} ) {
    print_example_config_file('hicup_example.conf');
    exit(0);
}

my @filenames = process_config( $config{config}, \%config ) if hasval($config{config});    #Modifies %config and returns an array of the filenames

if (@ARGV) {  
    if(scalar @ARGV % 2){
      die "There needs to be an even number of files specified in the command line, see hicup --help for more details.\n";
    }
    push( @filenames, @ARGV );                                  #Add filenames specified in the command line to those in the configuration file
}

unless( check_files_exist(\@filenames, 'EXISTS') ){
	die "Please adjust configuration.\n";
}

my %files = @filenames;                     #%files : hash of paired forward and reverse files
die "Only uniques filenames are allowed (irrespective of the path to the file).\n" unless check_no_duplicate_filename(%files);    #Check hash contains no duplicate filenames (irrespective of location)

print "Starting HiCUP pipeline (v$VERSION)\n" unless $config{quiet};

##########################################################
#Check user-supplied parameters are ok
unless ( check_parameters() ) {
    die "Please change configuration file and/or command-line parameters and/or installation accordingly\n";
}

#########################################################################
#Check files exist
#Check the input files exist
#Sequences, genome, digest
my $files_exist = 1;
unless ( -e $config{digest} ) {
    print "File '$config{digest}' does not exist.\n";
    $files_exist = 0;
}

foreach my $filenameF ( keys %files ) {
    my $filenameR = $files{$filenameF};
    unless ( -e $filenameF ) {
        print "Sequence file '$filenameF' does not exist.\n";
        $files_exist = 0;
    }
    unless ( -e $filenameR ) {
        print "Sequence file '$filenameR' does not exist.\n";
        $files_exist = 0;
    }
}

unless ($files_exist) {
    die "Please adjust the configuration file or add specified files.\n";
}

#Modify the outdir/temp directory setting as required
if( hasval($config{temp}) ) {
     if( hasval($config{outdir}) ){
        $config{originalOutdir} = $config{outdir};
     }else{
        $config{originalOutdir} = './';
     }

    ($config{temp}) = tempdir( 'HiCUP_temp_directory_XXXXXX', DIR => $config{temp});
    $config{temp} = $config{temp} . '/';
    $config{outdir} = $config{temp};    #Write future output to the temp directory
}


########################################################################
#Start the pipeline
my $sonication_protocol = 0;    #Is this a sonication or a double-digest protocol

if($config{digest} =~ /\.gz$/){
    open( DIGEST, "zcat $config{digest} |" ) or die "Couldn't read file '$config{digest}' : $!";
}else{
    open( DIGEST, $config{digest} ) or die "Cannot read file read file '$config{digest}' : $!";
}

my $header_line = scalar <DIGEST>;
unless ( $header_line =~ /^.+\t.+\t(.+)\t.+$/ ) {
    die "Genome digest file header is not in the correct format\n";
}

#Obtain the restriction enzyme 1 sequence from the digest file
if ( $1 eq "Restriction_Enzyme2:None" ) {    #Sonication protocol
    $sonication_protocol = 1;
}

if ( $config{sequence} ne '' ) {
    $config{re1} = '';
} else {
    print "Reading genome digest file '$config{digest}' to determine Hi-C restriction enzyme\n" unless $config{quiet};

    unless ( $header_line =~ /^.+\t.+\[(.+)\]\t.+/ ) {
        die "Genome digest file $config{digest} is not in the correct format.\n";
    }

    $config{re1} = $1;

    unless ( $config{re1} =~ /^[ATCG\^]+$/ ) {
        die "The restriction site (re1) needs to be a valid DNA sequence.\n";
    }
    unless ( ( $config{re1} =~ tr/\^// ) == 1 ) {
        die "The restriction site (re1) should contain one cut position, denoted by '^'.\n";
    }
}
close DIGEST;

#Determine the relevant output filename pairs
my %truncater_outputfiles    = predict_truncater_outputfiles(%files);
my %mapper_outputfiles       = predict_mapper_outputfiles(%truncater_outputfiles);      #mapper and pairer now combined into mapper
my @pairer_outputfiles       = predict_pairer_outputfiles(%mapper_outputfiles);
my @filter_outputfiles       = predict_filter_outputfiles(@pairer_outputfiles);
my @deduplicator_outputfiles = predict_deduplicator_outputfiles(@filter_outputfiles);

#Check the expected output files don't already exist
my $exists_already;
my @all_output_filenames = ( %truncater_outputfiles, %mapper_outputfiles, @pairer_outputfiles, @filter_outputfiles, @deduplicator_outputfiles );

foreach (@all_output_filenames) {
    if ( -e $config{outdir} . $_ ) {
        print "Outputfile $_ already exists.\n";
        $exists_already = 1;
    }
}

if ($exists_already) {
    die "Please delete files or adjust hicup configuration.\n";
}


#Add command line flags to relevant arguments
$config{ambiguous} = "-ambiguous"                if ( $config{ambiguous} ne '' );
$config{bowtie}    = "-bowtie $config{bowtie}"   if ( $config{bowtie} ne '' );
$config{bowtie2}   = "-bowtie2 $config{bowtie2}" if ( $config{bowtie2} ne '' );
my $datestamp      = datestamp();
my $datestamp_flag = "-datestamp $datestamp";    #Enables all summary files to have same datestamp
$config{digest} = "-digest $config{digest}" if ( $config{digest} ne '' );
$config{format} = "-format $config{format}" if ( $config{format} ne '' );
if ( $config{longest} ne '' ) {
    $config{longest} = "-longest $config{longest}";
}
my $outdir_flag = '';
$outdir_flag       = "-outdir $config{outdir}"     if ( $config{outdir} );           #This is the flag, not outdir
$config{nofill}    = "-nofill"                     if ( $config{nofill} ne '' );
$config{re1}       = "-re1 $config{re1}"           if ( $config{re1} ne '' );
$config{seq_trunc} = "-sequence $config{sequence}" if ( $config{sequence} ne '' );
if ( $config{shortest} ne '' ) {
    $config{shortest} = "-shortest $config{shortest}";
}

$config{quiet} = "-quiet" if ( $config{quiet} ne '' );
$config{zip}   = "-zip"   if ( $config{zip} ne '' );
$config{index} = "-index $config{index}";
$config{r} = "-r $config{r}";


#Run each hicup script in turn
#Pipeline will delete intermediate files, unless specified otherwise i.e. flag 'keep:'
#Pipeline will keep all summary files
#Pipeline will zip final output files if 'zip:' selected or zip all non-summary output files if zip and keep both selected
#All files will be kept in current folder, but a new folder shall be created for hicup_filter reject sequences

#Truncate sequences
#my $outdir_temp = $config{outdir};    #The original files will not be in the output directory, so change outdir temporarily
#$config{outdir} = './';
my $filenames_string = filename_string_generator(%files);

#$config{outdir} = $outdir_temp;
my $truncater_version;    #Stores the truncater version number 

$truncater_version = `$Bin/hicup_truncater -v` or die "Can't run hicup_truncater to determine version number\n.";

if ( $config{keep} and $config{zip} ) {
    !system("$Bin/hicup_truncater $config{r} $datestamp_flag $config{nofill} $outdir_flag $config{quiet} $config{re1} $config{sequence} $config{threads} $config{zip} $filenames_string") or die "Can't run hicup_truncater\n.";
} else {
    !system("$Bin/hicup_truncater $config{r} $datestamp_flag $config{nofill} $outdir_flag $config{quiet} $config{re1} $config{sequence} $config{threads} $filenames_string") or die "Can't run hicup_truncater\n.";
}

#Map and pair sequences
my $ligation = $truncater_version;    #Create the hidden ligation flag to send to HiCUP mapper to print the hicup_truncation settings to the output file
chomp $ligation;
$ligation = "\@PG\t" . $ligation;
if ( $config{re1} ) {
    $ligation = "\'" . $ligation . "\tRestriction enzyme: $config{re1}" . "\'";
} else {
    $ligation = "\'" . $ligation . "\tLigation junction sequences: $config{sequence}" . "\'";
}

$ligation = "--ligation $ligation";

$filenames_string = filename_string_generator(%truncater_outputfiles);

if ( $config{keep} and $config{zip} ) {
    !system("$Bin/hicup_mapper $config{r} $config{bowtie} $config{bowtie2} $config{ambiguous} $datestamp_flag $config{format} $outdir_flag $config{index} $ligation $config{quiet} $config{threads} $config{zip} $filenames_string") or die "Can't run hicup_mapper\n.";
} else {
    !system("$Bin/hicup_mapper $config{r} $config{bowtie} $config{bowtie2} $config{ambiguous} $datestamp_flag $config{format} $outdir_flag $config{index} $ligation $config{quiet} $config{threads} $filenames_string") or die "Can't run hicup_mapper\n.";
}

#Delete truncated intermediates
unless ( $config{keep} ) {
    foreach my $key ( keys %truncater_outputfiles ) {
        unlink $key or warn "Cannot delete '$key'.\n";    #First in the pair
        unlink $truncater_outputfiles{$key} or warn "Cannot delete '$truncater_outputfiles{$key}'.\n";    #Second in the pair
    }
}

#Filter files
$filenames_string = filename_string_generator_unpaired(@pairer_outputfiles);    #Use this subroutine for unpaired filenames

if ( $config{zip} and $config{keep} ) {
    !system("$Bin/hicup_filter $config{r} $datestamp_flag $config{digest} $config{longest} $outdir_flag $config{quiet} $config{shortest} $config{threads} $config{zip} $filenames_string") or die "Can't run hicup_filter.\n";
} else {
    !system("$Bin/hicup_filter $config{r} $datestamp_flag $config{digest} $config{longest} $outdir_flag $config{quiet} $config{shortest} $config{threads} $filenames_string") or die "Can't run hicup_filter.\n";
}

#Delete paired intermediates
unless ( $config{keep} ) {
    foreach (@pairer_outputfiles) {
            unlink $_ or warn "Cannot delete '$config{outdir}" . "$_'.\n";       
    }
}

#De-duplicate files
if(hasval ($config{temp}) ){    #Use send to outdir, if temp folder specified
   $config{outdir} = $config{originalOutdir}; 
    if ( hasval($config{outdir}) ){
        $outdir_flag = "--outdir $config{outdir}"
    }else{
        $outdir_flag = '';  
    }
}

$filenames_string = filename_string_generator_unpaired(@filter_outputfiles);    #Use this subroutine for unpaired filenames

if ( $config{zip} ) {                                                           #$keep not significant since this is the last step in the pipeline
    !system("$Bin/hicup_deduplicator $config{r} $datestamp_flag $outdir_flag $config{quiet} $config{threads} $config{zip} $filenames_string") or die "Can't run hicup_deduplicator.\n";
} else {
    !system("$Bin/hicup_deduplicator $config{r} $datestamp_flag $outdir_flag $config{quiet} $config{threads} $filenames_string") or die "Can't run hicup_deduplicator.\n";
}

#Delete paired intermediates
unless ( $config{keep} ) {
    foreach (@filter_outputfiles) {
            unlink $_ or warn "Cannot delete '$_'.\n";
    }
}

#Create the HTML summary output file
#Open each summary document in turn and write data into a hash of arrays %{filename} = $data
print "Creating HTML HiCUP summary report(s)\n";

#Reset the outdir/temp directory setting as required
if( hasval($config{temp}) ) {
    $config{outdir} = $config{temp};    #Look in temp directory
    $outdir_flag = "-outdir $config{outdir}"
}

my %truncater_summary;
open( TRUNCATER_SUMMARY, '<', $config{outdir} . "hicup_truncater_summary_$datestamp" . ".txt" ) or die "Could not open '" . $config{outdir} . "hicup_truncater_summary_$datestamp" . ".txt : $!";
scalar <TRUNCATER_SUMMARY>;    #Ignore header
while (<TRUNCATER_SUMMARY>) {
    my $line = $_;
    chomp $line;
    my @array = split( /\t/, $line );
    my $filename = shift @array;
    $filename = ( split( /\//, $filename ) )[-1];    #Filename only
    $truncater_summary{$filename} = [@array];
}
close TRUNCATER_SUMMARY or die "Could not close filehandle on 'hicup_truncater_summary_$datestamp.txt' : $!";

my %mapper_summary;
open( MAPPER_SUMMARY, '<', $config{outdir} . "hicup_mapper_summary_$datestamp" . ".txt" ) or die "Could not open '" . $config{outdir} . "hicup_mapper_summary_$datestamp" . ".txt : $!";
scalar <MAPPER_SUMMARY>;                             #Ignore header
while (<MAPPER_SUMMARY>) {
    my $line = $_;
    chomp $line;
    my @array = split( /\t/, $line );
    my $filename = shift @array;
    $mapper_summary{$filename} = [@array];
}
close MAPPER_SUMMARY or die "Could not close filehandle on 'hicup_mapper_summary_$datestamp.txt' : $!";

my %filter_summary;
open( FILTER_SUMMARY, '<', $config{outdir} . "hicup_filter_summary_$datestamp" . ".txt" ) or die "Could not open '" . $config{outdir} . "hicup_filter_summary_$datestamp" . ".txt : $!";
scalar <FILTER_SUMMARY>;                             #Ignore header
while (<FILTER_SUMMARY>) {
    my $line = $_;
    chomp $line;
    my @array = split( /\t/, $line );
    my $filename = shift @array;
    $filter_summary{$filename} = [@array];
}
close FILTER_SUMMARY or die "Could not close filehandle on 'hicup_filter_summary_$datestamp.txt' : $!";


#Reset the outdir/temp directory setting as required
if( hasval($config{temp}) ) {
    $config{outdir} = $config{originalOutdir};    #Use original output directory
 if ( hasval($config{outdir}) ){
        $outdir_flag = "--outdir $config{outdir}"
    }else{
        $outdir_flag = '';  
    }
}   

my %deduplicator_summary;
open( DEDUPLICATOR_SUMMARY, '<', $config{outdir} . "hicup_deduplicator_summary_$datestamp" . ".txt" ) or die "Could not open '" . $config{outdir} . "hicup_deduplicator_summary_$datestamp" . ".txt : $!";
scalar <DEDUPLICATOR_SUMMARY>;                       #Ignore header
while (<DEDUPLICATOR_SUMMARY>) {
    my $line = $_;
    chomp $line;
    my @array = split( /\t/, $line );
    my $filename = shift @array;
    $deduplicator_summary{$filename} = [@array];
}
close DEDUPLICATOR_SUMMARY or die "Could not close filehandle on 'hicup_deduplicator_summary_$datestamp.txt' : $!";

my @grouped_files;                                   #Array of arrays storing names of file_forward, file_reverse, file_combined for all the HiCUP steps

@pairer_outputfiles = sort @pairer_outputfiles;      #Ensure the file order is the same as for the sorted hashes
@filter_outputfiles = sort @filter_outputfiles;

my $i = 0;
foreach my $key ( sort keys %files ) {
    my $fileF = ( split( /\//, $key ) )[-1];         #Filename only
    my $fileR = $files{$key};
    $fileR = ( split( /\//, $fileR ) )[-1];          #Filename only

    push @{ $grouped_files[$i] }, $fileF;
    push @{ $grouped_files[$i] }, $fileR;
    $i++;
}

$i = 0;
foreach my $key ( sort keys %truncater_outputfiles ) {
    my $fileF = ( split( /\//, $key ) )[-1];         #Filename only
    my $fileR = $truncater_outputfiles{$key};
    $fileR = ( split( /\//, $fileR ) )[-1];          #Filename only

    push @{ $grouped_files[$i] }, $fileF;
    push @{ $grouped_files[$i] }, $fileR;
    $i++;
}

$i = 0;
foreach (@pairer_outputfiles) {
    my $file = ( split( /\//, $_ ) )[-1];            #Filename only
    push @{ $grouped_files[$i] }, $file;
    $i++;
}

$i = 0;
foreach (@filter_outputfiles) {
    my $file = ( split( /\//, $_ ) )[-1];            #Filename only
    push @{ $grouped_files[$i] }, $file;
    $i++;
}

#Open the template report
if ( -e "$Bin/hicup_report.html" ) {
    open( IN, '<', "$Bin/hicup_report.html" ) or die "Could not open $Bin/hicup_report.html : $!";
} else {
    warn "Skipping HTML report, could not locate $Bin/hicup_report.html.\n";
}

#Open the template report
if ( -e "$Bin/hicup_report.html" ) {
    open( TEMPLATE, '<', "$Bin/hicup_report.html" ) or die "Could not open '$Bin/hicup_report.html' : $!";
    my $template;

    while (<TEMPLATE>) {
        $template .= $_;
    }

    close TEMPLATE or die "Could not close filehandle on '$Bin/hicup_report.html' : $!";

    my @data;
    my $input_total_reads_1;
    my $input_total_reads_2;
    my $input_not_truncated_reads_1;
    my $input_not_truncated_reads_2;
    my $input_truncated_read_1;
    my $input_truncated_read_2;
    my $input_average_length_truncated_1;
    my $input_average_length_truncated_2;
    my $input_too_short_to_map_read_1;
    my $input_too_short_to_map_read_2;
    my $input_unique_alignments_read_1;
    my $input_unique_alignments_read_2;
    my $input_multiple_alignments_read_1;
    my $input_multiple_alignments_read_2;
    my $input_failed_to_align_read_1;
    my $input_failed_to_align_read_2;
    my $input_unpaired_read_1;
    my $input_unpaired_read_2;
    my $input_paired_read_1;
    my $input_paired_read_2;

    for my $i ( 0 .. $#grouped_files ) {

        #Create summary report file
        my $namePart1 = ( split( /\//, $grouped_files[$i][0] ) )[-1];
        my $namePart2 = ( split( /\//, $grouped_files[$i][0] ) )[-1];
        my $htmlFilename = $config{outdir} . $namePart1 . '_' . $namePart2 . ".html";

        open( REPORT, '>', $htmlFilename ) or die "Could not write to HTML HiCUP summary report '$htmlFilename' : $!";

        my $new_report = $template;

        $new_report =~ s/INPUT_FILENAME/$htmlFilename/g;
        $new_report =~ s/DATESTAMP/$datestamp/g;

        unless ( exists $truncater_summary{ $grouped_files[$i][0] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $truncater_summary{ $grouped_files[$i][0] } };

        $input_total_reads_1              = $data[0];
        $input_truncated_read_1           = $data[1];
        $input_not_truncated_reads_1      = $data[3];
        $input_average_length_truncated_1 = $data[5];

        $new_report =~ s/INPUT_TOTAL_READS_1/$input_total_reads_1/g;
        $new_report =~ s/INPUT_TRUNCATED_READ1/$input_truncated_read_1/g;
        $new_report =~ s/INPUT_NOT_TRUNCATED_READ1/$input_not_truncated_reads_1/g;
        $new_report =~ s/INPUT_AVERAGE_LENGTH_TRUNCATED_READ1/$input_average_length_truncated_1/g;

        unless ( exists $truncater_summary{ $grouped_files[$i][1] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $truncater_summary{ $grouped_files[$i][1] } };

        $input_total_reads_2              = $data[0];
        $input_truncated_read_2           = $data[1];
        $input_not_truncated_reads_2      = $data[3];
        $input_average_length_truncated_2 = $data[5];

        $new_report =~ s/INPUT_TOTAL_READS_2/$input_total_reads_2/g;
        $new_report =~ s/INPUT_TRUNCATED_READ2/$input_truncated_read_2/g;
        $new_report =~ s/INPUT_NOT_TRUNCATED_READ2/$input_not_truncated_reads_2/g;
        $new_report =~ s/INPUT_AVERAGE_LENGTH_TRUNCATED_READ2/$input_average_length_truncated_2/g;

        unless ( exists $mapper_summary{ $grouped_files[$i][2] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $mapper_summary{ $grouped_files[$i][2] } };

        $input_too_short_to_map_read_1    = $data[1];
        $input_unique_alignments_read_1   = $data[3];
        $input_multiple_alignments_read_1 = $data[5];
        $input_failed_to_align_read_1     = $data[7];
        $input_paired_read_1              = $data[9];

        $new_report =~ s/INPUT_TOO_SHORT_TO_MAP_READ_1/$input_too_short_to_map_read_1/g;
        $new_report =~ s/INPUT_UNIQUE_ALIGNMENTS_READ1/$input_unique_alignments_read_1/g;
        $new_report =~ s/INPUT_MULTIPLE_ALIGNMENTS_READ1/$input_multiple_alignments_read_1/g;
        $new_report =~ s/INPUT_FAILED_TO_ALIGN_READ1/$input_failed_to_align_read_1/g;
        $new_report =~ s/INPUT_PAIRED_READ1/$input_paired_read_1/g;

        unless ( exists $mapper_summary{ $grouped_files[$i][3] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $mapper_summary{ $grouped_files[$i][3] } };

        $input_too_short_to_map_read_2    = $data[1];
        $input_unique_alignments_read_2   = $data[3];
        $input_multiple_alignments_read_2 = $data[5];
        $input_failed_to_align_read_2     = $data[7];
        $input_paired_read_2              = $data[9];

        $new_report =~ s/INPUT_TOO_SHORT_TO_MAP_READ_2/$input_too_short_to_map_read_2/g;
        $new_report =~ s/INPUT_UNIQUE_ALIGNMENTS_READ2/$input_unique_alignments_read_2/g;
        $new_report =~ s/INPUT_MULTIPLE_ALIGNMENTS_READ2/$input_multiple_alignments_read_2/g;
        $new_report =~ s/INPUT_FAILED_TO_ALIGN_READ2/$input_failed_to_align_read_2/g;
        $new_report =~ s/INPUT_PAIRED_READ2/$input_paired_read_2/g;

        unless ( exists $filter_summary{ $grouped_files[$i][4] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $filter_summary{ $grouped_files[$i][4] } };

        my $input_valid_pairs;
        my $input_invalid_pairs;
        my $input_same_circularised;
        my $input_same_dangling_ends;
        my $input_same_fragment_internal;
        my $input_re_ligation;
        my $input_contiguous_sequence;
        my $input_wrong_size;
        my $input_total_pairs;

        my $input_no_ligation;
        my $input_no_ligation_internal_re2;
        my $input_unclassified;
        my $input_unmapped;
        my $input_self_ligation;

        my $input_deduplication_read_pairs_all;
        my $input_deduplication_cis_close_all;
        my $input_deduplication_cis_far_all;
        my $input_deduplication_trans_all;

        $input_deduplication_read_pairs_all = $data[1];
        $input_deduplication_cis_close_all  = $data[2];
        $input_deduplication_cis_far_all    = $data[3];
        $input_deduplication_trans_all      = $data[4];

        if ($sonication_protocol) {
            $input_valid_pairs            = $data[1];
            $input_invalid_pairs          = $data[5];
            $input_same_circularised      = $data[6];
            $input_same_dangling_ends     = $data[7];
            $input_same_fragment_internal = $data[8];
            $input_re_ligation            = $data[9];
            $input_contiguous_sequence    = $data[10];
            $input_wrong_size             = $data[11];
            $input_total_pairs            = $data[0];

            $new_report =~ s/INPUT_VALID_PAIRS/$input_valid_pairs/g;
            $new_report =~ s/INPUT_INVALID_PAIRS/$input_invalid_pairs/g;
            $new_report =~ s/INPUT_SAME_CIRCULARISED/$input_same_circularised/g;
            $new_report =~ s/INPUT_SAME_DANGLING_ENDS/$input_same_dangling_ends/g;
            $new_report =~ s/INPUT_SAME_FRAGMENT_INTERNAL/$input_same_fragment_internal/g;
            $new_report =~ s/INPUT_RE_LIGATION/$input_re_ligation/g;
            $new_report =~ s/INPUT_CONTIGUOUS_SEQUENCE/$input_contiguous_sequence/g;
            $new_report =~ s/INPUT_WRONG_SIZE/$input_wrong_size/g;
            $new_report =~ s/INPUT_TOTAL_PAIRS/$input_total_pairs/g;

        } else {
            $input_total_pairs              = $data[0];
            $input_valid_pairs              = $data[1];
            $input_invalid_pairs            = $data[5];
            $input_no_ligation              = $data[6];
            $input_re_ligation              = $data[7];
            $input_self_ligation            = $data[8];
            $input_no_ligation_internal_re2 = $data[9];
            $input_unclassified             = $data[10];
            $input_wrong_size               = $data[11];
            $input_unmapped                 = $data[12];

            $new_report =~ s/INPUT_TOTAL_PAIRS/$input_total_pairs/g;
            $new_report =~ s/INPUT_VALID_PAIRS/$input_valid_pairs/g;
            $new_report =~ s/INPUT_INVALID_PAIRS/$input_invalid_pairs/g;
            $new_report =~ s/INPUT_NO_LIGATION/ $input_no_ligation/g;
            $new_report =~ s/INPUT_RE_LIGATION/$input_re_ligation/g;
            $new_report =~ s/INPUT_SELF_LIGATION/$input_self_ligation/g;
            $new_report =~ s/INPUT_INTERNAL_RE2_NO_LIGATION/$input_no_ligation_internal_re2/g;
            $new_report =~ s/INPUT_UNCLASSIFIED/$input_unclassified/g;
            $new_report =~ s/INPUT_WRONG_SIZE/$input_wrong_size/g;
            $new_report =~ s/INPUT_UNMAPPED/$input_unmapped/g;
        }

        #Substitutions common to both protocols
        $new_report =~ s/INPUT_DEDUPLICATION_READ_PAIRS_ALL/$input_deduplication_read_pairs_all/g;
        $new_report =~ s/INPUT_DEDUPLICATION_CIS_CLOSE_ALL/$input_deduplication_cis_close_all/g;
        $new_report =~ s/INPUT_DEDUPLICATION_CIS_FAR_ALL/$input_deduplication_cis_far_all/g;
        $new_report =~ s/INPUT_DEDUPLICATION_TRANS_ALL/$input_deduplication_trans_all/g;

        unless ( exists $deduplicator_summary{ $grouped_files[$i][5] } ) {    #Some samples may not pass completely through the pipeline, so go to next loop if file does not exist
            next;
        }

        @data = @{ $deduplicator_summary{ $grouped_files[$i][5] } };

        my $input_deduplication_read_pairs_uniques = $data[1];
        my $input_deduplication_cis_close_uniques  = $data[2];
        my $input_deduplication_cis_far_uniques    = $data[3];
        my $input_deduplication_trans_uniques      = $data[4];

        my $percentage_uniques = 100 * $input_deduplication_read_pairs_uniques / $input_deduplication_read_pairs_all;
        $percentage_uniques = sprintf( "%.1f", $percentage_uniques );

        $new_report =~ s/INPUT_DEDUPLICATION_READ_PAIRS_UNIQUES/$input_deduplication_read_pairs_uniques/g;
        $new_report =~ s/INPUT_DEDUPLICATION_CIS_CLOSE_UNIQUES/$input_deduplication_cis_close_uniques/g;
        $new_report =~ s/INPUT_DEDUPLICATION_CIS_FAR_UNIQUES/$input_deduplication_cis_far_uniques/g;
        $new_report =~ s/INPUT_DEDUPLICATION_TRANS_UNIQUES/$input_deduplication_trans_uniques/g;
        $new_report =~ s/INPUT_DEDUPLICATION_PERCENTAGE_UNIQUES/$percentage_uniques/g;
        $new_report =~ s/INPUT_VERSION/$VERSION/g;

        #Edit the report to remove protocol-specific tags (in curly braces) (non-greedy match).
        if ($sonication_protocol) {
            $new_report =~ s/\{DOUBLE_DIGEST_TABLE_START\}[\w\s\n\r\S]*?\{DOUBLE_DIGEST_TABLE_END\}//g;
        } else {
            $new_report =~ s/\{SONICATION_TABLE_START\}[\w\s\n\r\S]*?\{SONICATION_TABLE_END\}//g;
        }

        $new_report =~ s/\{DOUBLE_DIGEST_TABLE_START\}//g;    #Remove remaining tags (non-greedy match)
        $new_report =~ s/\{DOUBLE_DIGEST_TABLE_END\}//g;
        $new_report =~ s/\{SONICATION_TABLE_START\}//g;
        $new_report =~ s/\{SONICATION_TABLE_END\}//g;

        #Edit te di-tag length table
        if ( $config{shortest} ne '' ) {                      #Remove '-shortest' from the Bowtie argument
            $config{shortest} =~ s/-shortest//;
            $new_report =~ s/INPUT_WIDTH_DITAG_LENGTH_SHORTEST/1/g;
            $new_report =~ s/INPUT_DITAG_LENGTH_SHORTEST/$config{shortest}/g;
        } else {
            $new_report =~ s/INPUT_WIDTH_DITAG_LENGTH_SHORTEST/0/g;
            $new_report =~ s/INPUT_DITAG_LENGTH_SHORTEST/0/g;    #Setting width to 0 makes the line invisible on the chart
        }

        if ( $config{longest} ne '' ) {
            $config{longest} =~ s/-longest//;                    #Remove '-longest' from the Bowtie argument
            $new_report =~ s/INPUT_WIDTH_DITAG_LENGTH_LONGEST/1/g;
            $new_report =~ s/INPUT_DITAG_LENGTH_LONGEST/$config{longest}/g;
        } else {
            $new_report =~ s/INPUT_WIDTH_DITAG_LENGTH_LONGEST/0/g;
            $new_report =~ s/INPUT_DITAG_LENGTH_LONGEST/0/g;     #Setting width to 0 makes the line invisible on the chart
        }

        #Open the ditag length temporary file to determine the di-tag lengths
        #Reset the outdir/temp directory setting as required
        if( hasval($config{temp}) ) {
            $config{outdir} = $config{temp};    #Look in temp directory
            $outdir_flag = "-outdir $config{outdir}"
        }

        my @paired_filename = predict_pairer_outputfiles( $grouped_files[$i][2], $grouped_files[$i][3] );
        my $ditag_length_summary = $config{outdir} . $paired_filename[0] . '.ditag_lengths.' . $datestamp . '.temp';

        open( DITAG_SUMMARY, '<', $ditag_length_summary ) or die "Could not open $ditag_length_summary : $!";

        scalar <DITAG_SUMMARY>;                                  #Ignore header
        my %ditag_length_frequencies;

        while (<DITAG_SUMMARY>) {
            chomp;
            my ( $length, $frequency ) = split(/\t/);
            $ditag_length_frequencies{$length} = $frequency;
        }

        close DITAG_SUMMARY or warn "Could not close $ditag_length_summary : $!";

        my $ditag_data_string = '';                              #Data string to add to the HTML file
        foreach my $length ( sort { $a <=> $b } keys %ditag_length_frequencies ) {
            $ditag_data_string .= '[' . $length . ', ' . $ditag_length_frequencies{$length} . '],';
        }

        $ditag_data_string =~ s/,$//;                            #Remove trailing comma
        unlink $ditag_length_summary or warn "Could not delete $ditag_length_summary : $!";
        $new_report =~ s/INPUT_DITAG_LENGTH_DATA/$ditag_data_string/g;
        print REPORT $new_report;
        close REPORT or die "Could not close filehandle on 'htmlFilename' :$!";

    }

} else {
    warn "Skipping HTML report, could not locate $Bin/hicup_report.html.\n";
}

#Clean up the --temp output folder and move relevant files to the output directory
if( hasval($config{temp}) ) {
    $config{outdir} = $config{originalOutdir};    #Use original output directory
    !system("mv $config{temp}/*.svg $config{temp}/*summary* $config{outdir}") or warn "Could not tidy temporary folder folder with command: 'mv $config{temp}/*.svg $config{temp}/*summary* $config{outdir}' : $!";
    remove_tree $config{temp} or warn "Could not delete temporary folder '$config{temp} with the command: 'remove_tree $config{temp}' : $!";
}

print "HiCUP processing complete.\n" unless $config{quiet};

exit (0);

#######################################################################################
#Subroutines                                                                          #
#######################################################################################

############################
#Subroutine "check_parameters":
#Check the user supplied parameters are ok
#Uses global variables
sub check_parameters {

    my $parameters_ok = 1;
	
	$parameters_ok = 0 unless ( checkAligner(\%config) );
	$parameters_ok = 0 unless ( checkAlignerIndices(\%config) );
    
    if( hasval($config{format}) ){    #Check specified FASTQ format is valid
        $parameters_ok = 0 unless(determineAlignerFormat($config{format}));
    }else{    #If FASTQ quality format not specified, determine this automatically
        my @sequence_files = %files;
        warn "FASTQ quality format not specified, analysing file '$sequence_files[0]' to predict file format used\n";
        $config{format} = quality_checker( $sequence_files[0] );

        if ( $config{format} eq 0 ) {
            die "Unable to determine FASTQ quality format, please specify this and re-run HiCUP.\n";
        } else {
            warn "FASTQ quality set to $config{format}\n";
        }
    }


    unless ( $config{digest} ) {
        print "Please specify a genome digest file.\n";
        $parameters_ok = 0;
    }
    unless ( hasval( $config{index} ) ) {
        print "Please specify reference genome indices for mapping.\n";
        $parameters_ok = 0;
    }

    if ( $config{longest} ne '' ) {
        unless ( $config{longest} =~ /^\d+$/ ) {
            print "'Longest' needs to specify the insert length in base pairs (i.e. is an integer)\n";
            $parameters_ok = 0;
        }
    }

    if ( $config{shortest} ne '' ) {
        unless ( $config{shortest} =~ /^\d+$/ ) {
            print "'Shortest' needs to specify the insert length in base pairs (i.e. is an integer)\n";
            $parameters_ok = 0;
        }
    }

    if ( ( $config{longest} ne '' ) and ( $config{shortest} ne '' ) ) {
        if ( $config{longest} =~ /^\d+$/ and $config{shortest} =~ /^\d+$/ ) {
            unless ( $config{shortest} < $config{longest} ) {
                print "The shortest allowable insert size should be smaller than the longest allowable insert size.\n";
                $parameters_ok = 0;
            }
        }
    }

    if ( $config{sequence} ne '' ) {
        my @ligation_sequences = split( /,/, $config{sequence} );    #Add directly to the global variable

        #Check all the ligation sequences are in the valid format ATCG_ATCG, where before '_' denotes sequence present in the genome reference
        foreach my $sequence (@ligation_sequences) {
            unless ( $sequence =~ /^[ATCG_]+$/ ) {
                warn "The ligation sequence $sequence is not a valid DNA sequence.\n";
                $parameters_ok = 0;
            }
            unless ( ( $sequence =~ tr/\_// ) == 1 ) {
                warn "The ligation sequence should define the position where the ligation sequence no longer matches the genome reference - denoted by \'_\'.\n";
                $parameters_ok = 0;
            }
        }
    }

    if ( $config{threads} ne '' ) {
        unless ( $config{threads} =~ /^\d+$/ ) {
            print "The specified 'Threads' value needs to be an integer.\n";
            $parameters_ok = 0;
        } else {
            $config{threads} = "-threads $config{threads}";
        }
    } else {
        $config{threads} = '-threads 1';
    }

    if ( $config{quiet} ne '' ) {    #May be defined as 0 in the config file
        unless ( $config{quiet} ) {
            $config{quiet} = '';
        }
    }

    if ( $config{nofill} ne '' ) {    #May be defined as 0 in the config file
        unless ( $config{nofill} ) {
            $config{nofill} = '';
        }
    }

    #Check SAMtools is installed
    if ( !system "which samtools >/dev/null 2>&1" ) {
        $config{samtools} = `which samtools`;
        chomp $config{samtools};
    } else {
        warn "Could not find SAMtools (http://samtools.sourceforge.net), please install if you wish to compress SAM files to BAM format\n";

    }

    #Check R installed
	checkR(\%config);

    #Check the output directory exists and allows write access
    if ( $config{outdir} ne '' ) {
        unless ( -d $config{outdir} ) {
            warn "Output directory '$config{outdir}' does not exist\n";
            $parameters_ok = 0;
        }

        unless ( $config{outdir} =~ /\/$/ ) {    #Make sure that $config{outdir} ends with the forward slash character
            $config{outdir} .= '/';
        }
    }

    if( hasval($config{temp}) ){
        if($config{keep}){
            warn "Option --temp may not be specified if --keep is also specified\n";
            $parameters_ok = 0;
        }else{
            unless ( -d $config{temp} ) {
                warn "Temporary directory '$config{temp}' does not exist\n";
                $parameters_ok = 0;
            }
        }
    }

    return $parameters_ok;
}

############################################
#Subroutine "predict_truncater_outputfiles":
#Receives the hicup_sorter output filename pair(s) and determines the hicup_truncater
#output filename pair(s).
sub predict_truncater_outputfiles {
    my (%input_files) = @_;
    my %output_files;

    for my $filename1 ( keys %input_files ) {
        my $filename2 = $input_files{$filename1};

        $filename1 =~ s/\.gz$|\.bz2$//;
        $filename1 =~ s/^.+\///;            #Remove folder references
        $filename1 =~ s/\.fq|\.fastq$//;    #Remove .fq or .fastq file extension
        $filename1 = $config{outdir} . $filename1;

        $filename1 .= "_trunc";

        $filename2 =~ s/\.gz$|\.bz2$//;
        $filename2 =~ s/^.+\///;            #Remove folder references
        $filename2 =~ s/\.fq|\.fastq$//;    #Remove .fq or .fastq file extension
        $filename2 .= "_trunc";
        $filename2 = $config{outdir} . $filename2;

        if ( $config{zip} and $config{keep} ) {
            $filename1 .= ".gz";
            $filename2 .= ".gz";
        }
        $output_files{$filename1} = $filename2;
    }

    return %output_files;

}

############################################
#Subroutine "predict_mapper_outputfiles":
#Receives the hicup_truncater output filename pair(s) and determines the hicup_mapper
#output filename pair(s).
sub predict_mapper_outputfiles {    #mapper and pairer now combined into mapper
    my (%input_files) = @_;
    my %output_files;

    for my $filename1 ( keys %input_files ) {
        my $filename2 = $input_files{$filename1};

        $filename1 =~ s/\.gz$//;
        $filename1 .= ".map";

        $filename2 =~ s/\.gz$//;
        $filename2 .= ".map";

        if ( $config{zip} and $config{keep} ) {
            $filename1 .= ".gz";
            $filename2 .= ".gz";
        }
        $output_files{$filename1} = $filename2;
    }

    return %output_files;

}

#########################################
#Subroutine "predict_pairer_outputfiles":
#Receives the hicup_mapper output filename pair(s) and determines the hicup_pairer
#output filename(s).
sub predict_pairer_outputfiles {    #mapper and pairer now combined into mapper
    my (%input_files) = @_;
    my @output_files;

    foreach my $fileforward ( keys %input_files ) {

        #Create the ".pair" outputfile
        my $outputfile1 = $fileforward;
        my $paired_filename;

        $outputfile1 =~ s/\.gz$//;
        $outputfile1 =~ s/\.map$//;

        my $outputfile2 = $input_files{$fileforward};
        $outputfile2 =~ s/^.+\///;    #Remove folder references
        $outputfile2 =~ s/\.gz$//;
        $outputfile2 =~ s/\.map$//;

        if ( $outputfile1 =~ /s_(\d)_(\d)_sequence/ ) {
            $paired_filename = $outputfile1;
            $paired_filename =~ s/s_(\d)_1_sequence/s_${1}_sequence/;
            $paired_filename .= ".pair";
        } else {
            $paired_filename = $outputfile1 . "_" . $outputfile2 . ".pair";
        }

        if ( $config{keep} and $config{zip} ) {
            $paired_filename .= '.gz';
        }

        push( @output_files, $paired_filename );

        if ( $config{ambiguous} ) {
            my $ambiguous_filename = $outputfile1 . '_' . $outputfile2 . '.ambiguous.pair';
            $ambiguous_filename .= '.gz' if $config{zip};
            push( @output_files, $ambiguous_filename );
        }
    }

    return @output_files;
}

#########################################
#Subroutine "predict_filter_outputfiles":
#Receives the hicup_pairer output filename(s) and determines the hicup_filter output
#filename(s)
sub predict_filter_outputfiles {
    my @input_files = @_;
    my @output_files;

    foreach my $output_filename (@input_files) {

        if ( $config{samtools} and $config{zip} and $config{keep} ) {
            $output_filename .= '.bam';
        } elsif ( $config{zip} and $config{keep} ) {
            $output_filename .= '.sam.gz';
        } else {
            $output_filename .= '.sam';
        }

        push( @output_files, $output_filename );
    }
    return @output_files;
}

###############################################
#Subroutine "predict_deduplicator_outputfiles:"
#Receives the hicup_filter output filename(s) and determines the hicup_deduplicator output
#filename(s)
sub predict_deduplicator_outputfiles {

    my @input_files = @_;
    my @output_files;

    foreach my $output_filename (@input_files) {

        $output_filename =~ s/\.gz$//;    #Remove the gzip file extension from the ouptfile name
        $output_filename =~ s/.sam$//;    #Remove '.sam' file extension
        $output_filename =~ s/.bam$//;    #Remove '.bam' file extension

        if ( $config{zip} and $config{samtools} ) {
            $output_filename = 'uniques_' . $output_filename . '.bam';
        } elsif ( $config{zip} ) {
            $output_filename = 'uniques_' . $output_filename . '.sam.gz';
        } else {
            $output_filename = 'uniques_' . $output_filename . '.sam';
        }

        push( @output_files, $output_filename );
    }
    return @output_files;
}

########################################
#Subroutine "filename_string_generator":
#Receives a hash of paired filenames which it uses to creates a string of the files to
#process. It also checks if those files are empty and if so removes them from the
#pipeline.
sub filename_string_generator {

    my (%filename_pairs) = @_;
    my $filenames_string = "";

    foreach my $filename1 ( keys %filename_pairs ) {
        my $filename2 = $filename_pairs{$filename1};

        #$filename1 = $config{outdir} . $filename1;
        #$filename2 = $config{outdir} . $filename2;

        my $filename1_contains_data = 0;
        my $filename2_contains_data = 0;

        unless ( ( -e $filename1 ) and ( -e $filename2 ) ) {    #Only check filesize of files that exist
            next;
        }

        #Identify empty unzipped/zipped files
        if ( $filename1 =~ /\.gz$/ ) {
            if ( ( -s $filename1 ) > 100 ) {                    #Only perform check on small files
                $filename1_contains_data = 1;
            } else {
                open( FILENAME1, "zcat $filename1 |" ) or die "Couldn't read file '$filename1' : $!";
                while (<FILENAME1>) {

                    if ( $_ =~ /\S/ ) {
                        $filename1_contains_data = 1;
                    }
                }
                close FILENAME1;
            }

            if ( ( -s $filename2 ) > 100 ) {    #    Only perform check on small files
                $filename2_contains_data = 1;
            } else {
                open( FILENAME2, "zcat $filename2 |" ) or die "Couldn't read file '$filename2' : $!";
                while (<FILENAME2>) {
                    if ( $_ =~ /\S/ ) {
                        $filename2_contains_data = 1;
                    }
                }
                close FILENAME2;
            }
        } else {
            if ( -s $filename1 ) {
                $filename1_contains_data = 1;
            }
            if ( -s $filename2 ) {
                $filename2_contains_data = 1;
            }
        }
        unless ($filename1_contains_data) {
            warn "$filename1 contains no data\n";
        }
        unless ($filename2_contains_data) {
            warn "$filename2 contains no data\n";
        }
        unless ( $filename1_contains_data + $filename2_contains_data == 2 ) {
            warn "$filename1 and $filename2 shall be processed no further\n";
        } else {
            $filenames_string .= "$filename1 $filename2 ";
        }
    }

    if ( $filenames_string eq "" ) {
        die "The remaining files in the HiCUP pipeline contain no data. Processing terminated.\n";
    } else {
        return $filenames_string;
    }
}

#################################################
#Subroutine "filename_string_generator_unpaired":
#receives filenames that do not need pairing (e.g. '.pair' files) which it uses to create
#a string of the files to process. It also checks if those files are empty and, if so,
#removes them from the pipeline.
sub filename_string_generator_unpaired {

    my @input_files      = @_;
    my $filenames_string = "";

    foreach my $inputfile (@input_files) {
        $inputfile = $inputfile;

        #print "$inputfile\n";

        unless ( -e $inputfile ) {    #Only check filesize of files that exist
            next;
        }

        if ( ( -s $inputfile ) < 10000 ) {    #Only check whether small files contain data

            #Open the inputfile
            if ( $inputfile =~ /\.gz$/ ) {    #Compressed SAM file
                open( INPUTFILE, "zcat $inputfile |" ) or die "Couldn't read file '$inputfile' : $!";
            } elsif ( $inputfile =~ /\.bam$/ ) {    #BAM file
                open( INPUTFILE, "$config{samtools} view -h $inputfile |" ) or die "Couldn't read file '$inputfile' : $!";
            } else {                                #SAM file
                open( INPUTFILE, $inputfile ) or die "Couldn't read file '$inputfile' : $!";
            }

            #Check whether the file contains data i.e. a line not beginning with '@'
            my $data_present = 0;
            while (<INPUTFILE>) {
                if (/^@/) {
                    next;
                }
                if (/\S/) {
                    $data_present = 1;              #Data found
                    last;
                }
            }

            if ($data_present) {
                $filenames_string .= "$inputfile ";
            } else {
                warn "$inputfile contains no data\n";
            }
        } else {
            $filenames_string .= "$inputfile ";     #File > 10000 in size, so assumed to contain data
        }
    }

    if ( $filenames_string eq "" ) {
        die "All the files in the HiCUP pipeline have been removed for containing no data.\n";
    } else {
        return $filenames_string;
    }
}

########################
#Subroutine "datestamp":
#creates a datestamp string
sub datestamp {
    my @now       = localtime();
    my $timeStamp = sprintf(
        "%02d-%02d-%02d_%02d-%02d-%04d",

        $now[2], $now[1],     $now[0],
        $now[3], $now[4] + 1, $now[5] + 1900
    );
    return $timeStamp;
}





__DATA__

HiCUP homepage: www.bioinformatics.babraham.ac.uk/projects/hicup

SYNOPSIS

hicup is used to run the whole HiCUP pipeline

hicup [OPTIONS]... -config [CONFIGURATION FILE]...
hicup [OPTIONS]... [FILES]

FUNCTION

The HiCUP pipeline receives FASTQ files and generates Hi-C paired read (di-tag)
files. The hicup script regulates the pipeline, passing output from one script to 
the next. 

The HiCUP pipeline uses a configuration file to set the mapping and filtering 
parameters. To produce an example configuration file:

hicup -example

Parameters may also be passed to HiCUP via the command line, overriding those 
specified in the configuration file. FASTQ file pairs should be place next to 
each other when using the command line, or on adjacent lines in the configuration 
file.

COMMAND LINE OPTIONS

--bowtie       Specify the path to Bowtie
--bowtie2      Specify the path to Bowtie 2
--config       Specify the configuration file
--example      Produce an example configuration file
--format       Specify FASTQ format
               Options: Sanger, Solexa_Illumina_1.0, Illumina_1.3, Illumina_1.5
--help         Print help message and exit
--keep         Keep intermediate pipeline files
--longest      Maximum allowable insert size (bps)
--nofill       Hi-C protocol did NOT include a fill-in of sticky ends prior to 
               ligation step and therefore FASTQ reads shall be truncated at the 
               Hi-C restriction enzyme cut site (if present) sequence is 
               encountered
--outdir       Directory to write output files
--quiet	       Suppress progress reports (except warnings)
--shortest     Minimum allowable insert size (bps)
--temp         Write intermediate files (i.e. all except summary files and files
               generated by HiCUP Deduplicator) to a specified directory
--threads      Specify the number of threads, allowing simultaneous processing 
               of multiple files
--version      Print the program version and exit
--zip          Compress output

Full instructions on running the pipeline can be found at:
www.bioinformatics.babraham.ac.uk/projects/hicup

Steven Wingett, Babraham Institute, Cambridge, UK (steven.wingett@babraham.ac.uk)
